{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "123df880-0a85-42c4-b5f4-28772587a4fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing ---\n",
      "BERT model loaded with 12 layers.\n",
      "Model is on device: cuda\n",
      "CUDA is available: True\n",
      "Current CUDA device name: NVIDIA GeForce RTX 3050 Laptop GPU\n",
      "\n",
      "--- Input Tensor Information ---\n",
      "Input IDs shape: torch.Size([2, 256])\n",
      "Attention Mask shape: torch.Size([2, 256])\n",
      "Token Type IDs shape: torch.Size([2, 256])\n",
      "\n",
      "--- Starting Profiling ---\n",
      "Saving trace file to: C:\\Users\\vaibh\\Downloads\\pytorch\\bert_trace_logs_with_gpu\n",
      "\n",
      "--- Profiling Complete ---\n",
      "Trace files saved.\n",
      "\n",
      "--- Aggregated Profiler Results (milliseconds) ---\n",
      "=====================================================================================================================================================================================================================================================\n",
      "Top CUDA Time Operations\n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                    ProfilerStep*         0.08%     381.495us         0.08%     381.495us      76.299us     475.661ms        50.05%     475.661ms      95.132ms           0 b           0 b           0 b           0 b             5  \n",
      "                                     aten::linear        13.17%      63.385ms        38.43%     185.020ms     506.905us      29.103ms         3.06%     241.214ms     660.860us           0 b           0 b     836.53 Mb           0 b           365  \n",
      "                                      aten::addmm        11.29%      54.373ms        11.29%      54.373ms     148.967us     142.418ms        14.99%     142.418ms     390.186us           0 b           0 b     836.53 Mb     836.53 Mb           365  \n",
      "                            BERT_inference_step_7         7.38%      35.521ms        23.03%     110.856ms     110.856ms      21.149ms         2.23%     110.898ms     110.898ms           0 b        -192 b      -8.25 Mb    -349.77 Mb             1  \n",
      "                            BERT_inference_step_4         7.08%      34.063ms        22.89%     110.189ms     110.189ms      19.966ms         2.10%     110.255ms     110.255ms           0 b        -192 b       9.25 Mb    -343.02 Mb             1  \n",
      "                            BERT_inference_step_3         6.20%      29.837ms        19.73%      94.995ms      94.995ms      13.664ms         1.44%      88.397ms      88.397ms         168 b         -24 b      -9.75 Mb    -350.27 Mb             1  \n",
      "                            BERT_inference_step_5         5.28%      25.429ms        17.45%      84.019ms      84.019ms      12.484ms         1.31%      84.053ms      84.053ms           0 b        -192 b      -8.75 Mb    -348.27 Mb             1  \n",
      "                            BERT_inference_step_6         5.61%      27.024ms        16.82%      80.952ms      80.952ms      13.838ms         1.46%      81.014ms      81.014ms           0 b        -192 b       8.25 Mb    -342.02 Mb             1  \n",
      "               aten::scaled_dot_product_attention         1.38%       6.661ms        10.61%      51.088ms     851.473us       5.113ms         0.54%      60.016ms       1.000ms         960 b           0 b      94.91 Mb           0 b            60  \n",
      "    aten::_scaled_dot_product_efficient_attention         2.70%      13.005ms         8.53%      41.079ms     684.642us       6.513ms         0.69%      50.756ms     845.933us         960 b           0 b      94.91 Mb           0 b            60  \n",
      "                                 aten::layer_norm         1.16%       5.590ms         8.61%      41.452ms     331.613us       6.609ms         0.70%      44.001ms     352.008us           0 b           0 b     202.74 Mb           0 b           125  \n",
      "                                          aten::t         4.07%      19.577ms         8.44%      40.615ms     111.274us      18.812ms         1.98%      43.288ms     118.597us           0 b           0 b           0 b           0 b           365  \n",
      "                                  aten::transpose         6.73%      32.388ms         7.36%      35.423ms      53.267us      26.090ms         2.75%      38.845ms      58.414us           0 b           0 b           0 b           0 b           665  \n",
      "                          aten::native_layer_norm         6.39%      30.764ms         7.45%      35.862ms     286.896us      24.163ms         2.54%      37.392ms     299.136us           0 b           0 b     202.74 Mb           0 b           125  \n",
      "               aten::_efficient_attention_forward         2.89%      13.926ms         3.41%      16.431ms     273.852us      24.426ms         2.57%      31.081ms     518.017us         960 b           0 b      94.91 Mb           0 b            60  \n",
      "                                    aten::reshape         4.20%      20.201ms         5.44%      26.183ms      60.191us      17.984ms         1.89%      28.797ms      66.200us           0 b           0 b           0 b           0 b           435  \n",
      "                                       aten::view         2.83%      13.607ms         2.83%      13.607ms      10.973us      20.007ms         2.11%      20.007ms      16.135us           0 b           0 b           0 b           0 b          1240  \n",
      "                                 aten::as_strided         1.04%       5.025ms         1.04%       5.025ms       5.262us      18.835ms         1.98%      18.835ms      19.723us           0 b           0 b           0 b           0 b           955  \n",
      "                                      aten::empty         1.30%       6.281ms         1.30%       6.281ms       9.892us      15.424ms         1.62%      15.424ms      24.290us         960 b         960 b     300.14 Mb     300.14 Mb           635  \n",
      "                                    aten::permute         2.20%      10.601ms         2.52%      12.113ms      67.292us       9.226ms         0.97%      13.270ms      73.722us           0 b           0 b           0 b           0 b           180  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 481.392ms\n",
      "Self CUDA time total: 950.278ms\n",
      "\n",
      "=====================================================================================================================================================================================================================================================\n",
      "Top CPU Time Operations\n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                     aten::linear        13.17%      63.385ms        38.43%     185.020ms     506.905us      29.103ms         3.06%     241.214ms     660.860us           0 b           0 b     836.53 Mb           0 b           365  \n",
      "                            BERT_inference_step_7         7.38%      35.521ms        23.03%     110.856ms     110.856ms      21.149ms         2.23%     110.898ms     110.898ms           0 b        -192 b      -8.25 Mb    -349.77 Mb             1  \n",
      "                            BERT_inference_step_4         7.08%      34.063ms        22.89%     110.189ms     110.189ms      19.966ms         2.10%     110.255ms     110.255ms           0 b        -192 b       9.25 Mb    -343.02 Mb             1  \n",
      "                            BERT_inference_step_3         6.20%      29.837ms        19.73%      94.995ms      94.995ms      13.664ms         1.44%      88.397ms      88.397ms         168 b         -24 b      -9.75 Mb    -350.27 Mb             1  \n",
      "                            BERT_inference_step_5         5.28%      25.429ms        17.45%      84.019ms      84.019ms      12.484ms         1.31%      84.053ms      84.053ms           0 b        -192 b      -8.75 Mb    -348.27 Mb             1  \n",
      "                            BERT_inference_step_6         5.61%      27.024ms        16.82%      80.952ms      80.952ms      13.838ms         1.46%      81.014ms      81.014ms           0 b        -192 b       8.25 Mb    -342.02 Mb             1  \n",
      "                                      aten::addmm        11.29%      54.373ms        11.29%      54.373ms     148.967us     142.418ms        14.99%     142.418ms     390.186us           0 b           0 b     836.53 Mb     836.53 Mb           365  \n",
      "               aten::scaled_dot_product_attention         1.38%       6.661ms        10.61%      51.088ms     851.473us       5.113ms         0.54%      60.016ms       1.000ms         960 b           0 b      94.91 Mb           0 b            60  \n",
      "                                 aten::layer_norm         1.16%       5.590ms         8.61%      41.452ms     331.613us       6.609ms         0.70%      44.001ms     352.008us           0 b           0 b     202.74 Mb           0 b           125  \n",
      "    aten::_scaled_dot_product_efficient_attention         2.70%      13.005ms         8.53%      41.079ms     684.642us       6.513ms         0.69%      50.756ms     845.933us         960 b           0 b      94.91 Mb           0 b            60  \n",
      "                                          aten::t         4.07%      19.577ms         8.44%      40.615ms     111.274us      18.812ms         1.98%      43.288ms     118.597us           0 b           0 b           0 b           0 b           365  \n",
      "                          aten::native_layer_norm         6.39%      30.764ms         7.45%      35.862ms     286.896us      24.163ms         2.54%      37.392ms     299.136us           0 b           0 b     202.74 Mb           0 b           125  \n",
      "                                  aten::transpose         6.73%      32.388ms         7.36%      35.423ms      53.267us      26.090ms         2.75%      38.845ms      58.414us           0 b           0 b           0 b           0 b           665  \n",
      "                                    aten::reshape         4.20%      20.201ms         5.44%      26.183ms      60.191us      17.984ms         1.89%      28.797ms      66.200us           0 b           0 b           0 b           0 b           435  \n",
      "               aten::_efficient_attention_forward         2.89%      13.926ms         3.41%      16.431ms     273.852us      24.426ms         2.57%      31.081ms     518.017us         960 b           0 b      94.91 Mb           0 b            60  \n",
      "                                       aten::view         2.83%      13.607ms         2.83%      13.607ms      10.973us      20.007ms         2.11%      20.007ms      16.135us           0 b           0 b           0 b           0 b          1240  \n",
      "                                    aten::permute         2.20%      10.601ms         2.52%      12.113ms      67.292us       9.226ms         0.97%      13.270ms      73.722us           0 b           0 b           0 b           0 b           180  \n",
      "                                        aten::add         1.83%       8.820ms         1.83%       8.820ms      70.561us       7.755ms         0.82%       7.755ms      62.040us           0 b           0 b     199.00 Mb     199.00 Mb           125  \n",
      "                                 aten::is_nonzero         0.04%     199.300us         1.45%       6.999ms       1.400ms     237.000us         0.02%       1.059ms     211.800us           0 b           0 b           0 b           0 b             5  \n",
      "                                       aten::item         0.05%     255.400us         1.41%       6.799ms       1.360ms     196.000us         0.02%     822.000us     164.400us           0 b           0 b           0 b           0 b             5  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 481.392ms\n",
      "Self CUDA time total: 950.278ms\n",
      "\n",
      "=====================================================================================================================================================================================================================================================\n",
      "Top CUDA Memory Usage\n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                             Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg       CPU Mem  Self CPU Mem      CUDA Mem  Self CUDA Mem    # of Calls  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                      aten::addmm        11.29%      54.373ms        11.29%      54.373ms     148.967us     142.418ms        14.99%     142.418ms     390.186us           0 b           0 b     836.53 Mb     836.53 Mb           365  \n",
      "                                       aten::gelu         0.68%       3.289ms         0.68%       3.289ms      54.823us       4.495ms         0.47%       4.495ms      74.917us           0 b           0 b     364.00 Mb     364.00 Mb            60  \n",
      "                                      aten::empty         1.30%       6.281ms         1.30%       6.281ms       9.892us      15.424ms         1.62%      15.424ms      24.290us         960 b         960 b     300.14 Mb     300.14 Mb           635  \n",
      "                                        aten::add         1.83%       8.820ms         1.83%       8.820ms      70.561us       7.755ms         0.82%       7.755ms      62.040us           0 b           0 b     199.00 Mb     199.00 Mb           125  \n",
      "                                    aten::resize_         0.04%     191.200us         0.04%     191.200us      12.747us     343.000us         0.04%     343.000us      22.867us           0 b           0 b      18.75 Mb      18.75 Mb            15  \n",
      "                              aten::empty_strided         0.02%     117.900us         0.02%     117.900us      11.790us     244.000us         0.03%     244.000us      24.400us           0 b           0 b       3.12 Mb       3.12 Mb            10  \n",
      "                                        aten::sub         0.06%     267.700us         0.06%     267.700us      53.540us     323.000us         0.03%     323.000us      64.600us           0 b           0 b       2.50 Mb       2.50 Mb             5  \n",
      "                                       aten::tanh         0.07%     349.400us         0.07%     349.400us      69.880us     437.000us         0.05%     437.000us      87.400us           0 b           0 b      30.00 Kb      30.00 Kb             5  \n",
      "                                         aten::eq         0.09%     409.200us         0.09%     409.200us      81.840us     470.000us         0.05%     470.000us      94.000us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
      "                                        aten::all         0.10%     487.800us         0.11%     508.400us     101.680us     473.000us         0.05%     581.000us     116.200us           0 b           0 b       2.50 Kb       2.50 Kb             5  \n",
      "                                      aten::slice         0.36%       1.719ms         0.38%       1.807ms      72.268us       1.721ms         0.18%       2.176ms      87.040us           0 b           0 b           0 b           0 b            25  \n",
      "                                 aten::as_strided         1.04%       5.025ms         1.04%       5.025ms       5.262us      18.835ms         1.98%      18.835ms      19.723us           0 b           0 b           0 b           0 b           955  \n",
      "                                  aten::embedding         0.35%       1.708ms         0.93%       4.457ms     297.153us       1.135ms         0.12%       4.928ms     328.533us           0 b           0 b      18.75 Mb           0 b            15  \n",
      "                                    aten::reshape         4.20%      20.201ms         5.44%      26.183ms      60.191us      17.984ms         1.89%      28.797ms      66.200us           0 b           0 b           0 b           0 b           435  \n",
      "                                       aten::view         2.83%      13.607ms         2.83%      13.607ms      10.973us      20.007ms         2.11%      20.007ms      16.135us           0 b           0 b           0 b           0 b          1240  \n",
      "                               aten::index_select         0.38%       1.849ms         0.44%       2.138ms     142.553us       1.918ms         0.20%       2.584ms     172.267us           0 b           0 b      18.75 Mb           0 b            15  \n",
      "                                       aten::add_         0.07%     341.500us         0.07%     341.500us      68.300us     426.000us         0.04%     426.000us      85.200us           0 b           0 b           0 b           0 b             5  \n",
      "                                 aten::layer_norm         1.16%       5.590ms         8.61%      41.452ms     331.613us       6.609ms         0.70%      44.001ms     352.008us           0 b           0 b     202.74 Mb           0 b           125  \n",
      "                          aten::native_layer_norm         6.39%      30.764ms         7.45%      35.862ms     286.896us      24.163ms         2.54%      37.392ms     299.136us           0 b           0 b     202.74 Mb           0 b           125  \n",
      "                                    aten::dropout         0.08%     382.200us         0.08%     382.200us       3.058us       1.239ms         0.13%       1.239ms       9.912us           0 b           0 b           0 b           0 b           125  \n",
      "-------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 481.392ms\n",
      "Self CUDA time total: 950.278ms\n",
      "\n",
      "\n",
      "--- Example Model Output Shape (last_hidden_state) ---\n",
      "Last hidden state shape: torch.Size([2, 256, 768])\n",
      "Pooled output shape: torch.Size([2, 768])\n",
      "\n",
      "Remember to open the full trace file in chrome://tracing or Perfetto for detailed timeline analysis.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "import os\n",
    "\n",
    "print(\"--- Initializing ---\")\n",
    "\n",
    "# Load pre-trained tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Set the model to evaluation mode (important for consistent behavior and disabling dropout)\n",
    "model.eval()\n",
    "\n",
    "# Check for CUDA availability and set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device) # <--- COMMUNICATION: Model parameters are transferred from CPU to GPU memory here.\n",
    "\n",
    "print(f\"BERT model loaded with {model.config.num_hidden_layers} layers.\")\n",
    "print(f\"Model is on device: {device}\")\n",
    "print(f\"CUDA is available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Current CUDA device name: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "# Example text\n",
    "text = \"Hello, how are you doing today? This is an example sentence for BERT.\"\n",
    "# To increase GPU activity for a better trace, let's make the input longer and create a small batch\n",
    "long_text = \" \".join([text] * 10) # Repeat the sentence to make it longer\n",
    "batch_texts = [long_text, \"Another slightly different sentence for the batch.\"] # Create a batch of 2 sentences\n",
    "\n",
    "# Tokenize and prepare input tensors\n",
    "# Using padding=True (default pads to longest in batch) or 'max_length' for consistent size\n",
    "inputs = tokenizer(batch_texts, return_tensors='pt', padding='max_length', truncation=True, max_length=256) # Increased max_length to 256\n",
    "\n",
    "# Move inputs to the same device as the model\n",
    "input_ids = inputs['input_ids'].to(device)         # <--- COMMUNICATION: Input data transferred from CPU to GPU\n",
    "attention_mask = inputs['attention_mask'].to(device) # <--- COMMUNICATION: Input data transferred from CPU to GPU\n",
    "token_type_ids = inputs['token_type_ids'].to(device) if 'token_type_ids' in inputs else None # <--- COMMUNICATION (if present): Input data transferred from CPU to GPU\n",
    "\n",
    "print(f\"\\n--- Input Tensor Information ---\")\n",
    "print(f\"Input IDs shape: {input_ids.shape}\")\n",
    "print(f\"Attention Mask shape: {attention_mask.shape}\")\n",
    "if token_type_ids is not None:\n",
    "    print(f\"Token Type IDs shape: {token_type_ids.shape}\")\n",
    "else:\n",
    "    print(\"Token Type IDs are not present (common for single segment tasks).\")\n",
    "\n",
    "# Define the directory to save the trace file\n",
    "log_dir = \"bert_trace_logs_with_gpu\" # Changed log dir name to avoid conflicts\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "\n",
    "print(f\"\\n--- Starting Profiling ---\")\n",
    "print(f\"Saving trace file to: {os.path.abspath(log_dir)}\")\n",
    "\n",
    "# Use the profiler context manager\n",
    "with profile(\n",
    "    activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "    schedule=torch.profiler.schedule(wait=1, warmup=2, active=5, repeat=1),\n",
    "    on_trace_ready=torch.profiler.tensorboard_trace_handler(log_dir),\n",
    "    record_shapes=True,\n",
    "    profile_memory=True,\n",
    "    with_stack=True\n",
    ") as prof:\n",
    "    for i in range(8):\n",
    "        with record_function(f\"BERT_inference_step_{i}\"):\n",
    "            output = model(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids)\n",
    "        prof.step() # Signals the profiler to move to the next step in its schedule\n",
    "\n",
    "print(\"\\n--- Profiling Complete ---\")\n",
    "print(\"Trace files saved.\")\n",
    "\n",
    "# Print the aggregated results\n",
    "print(\"\\n--- Aggregated Profiler Results (milliseconds) ---\")\n",
    "# key_averages() provides an EventList with aggregated stats for each unique operation.\n",
    "# table() formats these stats into a readable table.\n",
    "# sort_by: Choose what to sort by (e.g., \"cuda_time_total\", \"self_cuda_time_total\", \"cpu_time_total\")\n",
    "# row_limit: Limit the number of rows to display (e.g., top 20 or more)\n",
    "# header: Customize the header if needed\n",
    "print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=20, header=\"Top CUDA Time Operations\"))\n",
    "print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=20, header=\"Top CPU Time Operations\"))\n",
    "print(prof.key_averages().table(sort_by=\"self_cuda_memory_usage\", row_limit=20, header=\"Top CUDA Memory Usage\"))\n",
    "\n",
    "\n",
    "# You can access the model output here if you need to inspect it\n",
    "# The output typically includes `last_hidden_state` and `pooler_output`\n",
    "print(f\"\\n--- Example Model Output Shape (last_hidden_state) ---\")\n",
    "if hasattr(output, 'last_hidden_state'):\n",
    "    print(f\"Last hidden state shape: {output.last_hidden_state.shape}\")\n",
    "if hasattr(output, 'pooler_output'):\n",
    "    print(f\"Pooled output shape: {output.pooler_output.shape}\")\n",
    "\n",
    "print(\"\\nRemember to open the full trace file in chrome://tracing or Perfetto for detailed timeline analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c39cb57-aa96-4ef6-a356-1ed6c94422ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
