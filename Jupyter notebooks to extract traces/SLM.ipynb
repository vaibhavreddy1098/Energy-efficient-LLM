{"cells":[{"cell_type":"markdown","id":"Bc9lOBTLzGxL","metadata":{"id":"Bc9lOBTLzGxL"},"source":[]},{"cell_type":"code","execution_count":58,"id":"9ca77536","metadata":{"executionInfo":{"elapsed":1674,"status":"ok","timestamp":1739546848724,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"9ca77536"},"outputs":[],"source":["import os\n","import nltk\n","from nltk.corpus import reuters"]},{"cell_type":"code","execution_count":59,"id":"4e9a0e24","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739546849340,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"4e9a0e24","outputId":"c9ae43da-3bf5-4177-cfa4-8f97f8c86b75"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package reuters to /root/nltk_data...\n","[nltk_data]   Package reuters is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":59}],"source":["nltk.download('reuters')"]},{"cell_type":"code","execution_count":60,"id":"c419deeb","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1739546849340,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"c419deeb"},"outputs":[],"source":["# Create a directory to store the text files\n","os.makedirs('data', exist_ok=True)"]},{"cell_type":"code","execution_count":61,"id":"c4b9573a","metadata":{"executionInfo":{"elapsed":9630,"status":"ok","timestamp":1739546858969,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"c4b9573a"},"outputs":[],"source":["# Iterate through the fileids in the Reuters corpus\n","for fileid in reuters.fileids():\n","    # Retrieve the text of the news article\n","    article_text = ' '.join(reuters.words(fileid))\n","\n","    # Construct the filename (you can also use\n","    # the categories in the filename if needed)\n","    filename = f'data/{fileid.replace(\"/\", \"_\")}.txt'\n","\n","    # Write the article text to a file\n","    with open(filename, 'w', encoding='utf-8') as file:\n","        file.write(article_text)"]},{"cell_type":"code","execution_count":62,"id":"dfb098ce","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7061,"status":"ok","timestamp":1739546866028,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"dfb098ce","outputId":"5b60119d-6f6f-4556-d24a-4896ca4d365b"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"]}],"source":["nltk.download('punkt')\n","import os\n","import string\n","\n","## Keep your training documents in a folder named 'data'\n","input_data_dir = \"data\"\n","\n","# String of punctuation without the full stop\n","punctuation = string.punctuation.replace('.', '')  # Retain the full stop\n","\n","def is_hidden(filepath):\n","    return os.path.basename(filepath).startswith('.')\n","\n","text_data=\"\"\n","for filename in os.listdir(input_data_dir):\n","    filepath = os.path.join(input_data_dir, filename)\n","    if not is_hidden(filepath):\n","        with open(filepath) as infile:\n","            for line in infile:\n","                if line.strip():  # Check if line is not just whitespace\n","                    # Remove all punctuation except full stops\n","                    for char in punctuation:\n","                        line = line.replace(char, '')\n","                    text_data += line\n"]},{"cell_type":"code","execution_count":63,"id":"8hMJdAJBcDj1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739546866029,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"8hMJdAJBcDj1","outputId":"75b1dab5-bafd-4130-c39e-9bba91ce06a7"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8441833"]},"metadata":{},"execution_count":63}],"source":["len(text_data)"]},{"cell_type":"code","execution_count":64,"id":"_Pp8epPRfLnT","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19844,"status":"ok","timestamp":1739546885870,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"_Pp8epPRfLnT","outputId":"eeab4fdc-c163-435d-a2e0-17738aa4a495"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]}],"source":["!pip install nltk\n","import nltk\n","\n","# Download 'punkt_tab' before tokenizing the text\n","nltk.download('punkt_tab')\n","\n","import os\n","import string\n","\n","## Keep your training documents in a folder named 'data'\n","input_data_dir = \"data\"\n","\n","# String of punctuation without the full stop\n","punctuation = string.punctuation.replace('.', '')  # Retain the full stop\n","\n","def is_hidden(filepath):\n","    return os.path.basename(filepath).startswith('.')\n","\n","text_data=\"\"\n","for filename in os.listdir(input_data_dir):\n","    filepath = os.path.join(input_data_dir, filename)\n","    if not is_hidden(filepath):\n","        with open(filepath) as infile:\n","            for line in infile:\n","                if line.strip():  # Check if line is not just whitespace\n","                    # Remove all punctuation except full stops\n","                    for char in punctuation:\n","                        line = line.replace(char, '')\n","                    text_data += line\n","\n","# Tokenize the text into words\n","# Lowercasing for consistency\n","words = nltk.word_tokenize(text_data.lower())\n","\n","#Rest of the user's code"]},{"cell_type":"code","execution_count":65,"id":"aZ_uyyslf6cK","metadata":{"id":"aZ_uyyslf6cK","executionInfo":{"status":"ok","timestamp":1739546905163,"user_tz":-330,"elapsed":19296,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"}}},"outputs":[],"source":["import nltk\n","from nltk.util import bigrams\n","from nltk import FreqDist\n","\n","# Tokenize the text into words\n","# Lowercasing for consistency\n","words = nltk.word_tokenize(text_data.lower())\n","\n","# Generate bigrams\n","bi_grams = list(bigrams(words)) # Now 'bigrams' is recognized\n","\n","# Calculate frequency distribution for each bigram\n","bi_gram_freq_dist = FreqDist(bi_grams)"]},{"cell_type":"code","execution_count":66,"id":"bUc-0RJNgArm","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739546905163,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"bUc-0RJNgArm","outputId":"cb03a51e-c059-4f74-d183-116d40e52953"},"outputs":[{"output_type":"stream","name":"stdout","text":["(('cable', 'unimpressed'), 1)\n","(('unimpressed', 'by'), 1)\n","(('by', 'new'), 37)\n","(('new', 'japanese'), 6)\n","(('japanese', 'telecoms'), 1)\n"]}],"source":["from itertools import islice\n","# Print the first five elements of the dictionary\n","first_five_items = list(islice(bi_gram_freq_dist.items(), 5))\n","for item in first_five_items:\n","    print(item)"]},{"cell_type":"code","execution_count":67,"id":"3K86GFv4gkNh","metadata":{"executionInfo":{"elapsed":3128,"status":"ok","timestamp":1739546908289,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"3K86GFv4gkNh"},"outputs":[],"source":["import nltk\n","from nltk.util import bigrams\n","from nltk.probability import ConditionalFreqDist  # Import ConditionalFreqDist\n","\n","# ... (rest of your code)\n","\n","# Compute conditional frequency distribution of bigrams\n","bi_gram_freq = ConditionalFreqDist(bi_grams)"]},{"cell_type":"code","execution_count":68,"id":"Bx4d-ojIgnE5","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739546908289,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"Bx4d-ojIgnE5","outputId":"0911a276-82ee-416e-8cfa-920554af9d2f"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["FreqDist({'gas': 216, 'rubber': 39, 'resources': 9, 'float': 3, 'for': 3, 'that': 2, 'lt': 2, 'disasters': 2, 'gasoline': 1, 'resource': 1, ...})"]},"metadata":{},"execution_count":68}],"source":["bi_gram_freq['natural']"]},{"cell_type":"code","execution_count":69,"id":"XjzSjndVgtY5","metadata":{"executionInfo":{"elapsed":1600,"status":"ok","timestamp":1739546909887,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"XjzSjndVgtY5"},"outputs":[],"source":["import heapq\n","\n","topk=3\n","# Create a dictionary to hold the top topk bigrams for each first word\n","top_bigrams_per_first_word = {}\n","\n","# Iterate over the bigram frequency distribution\n","for (first_word, second_word), freq in bi_gram_freq_dist.items():\n","    # Initialize an empty heap for the first_word if it doesn't exist\n","    if first_word not in top_bigrams_per_first_word:\n","        top_bigrams_per_first_word[first_word] = []\n","\n","    # Add to the heap and maintain top topk\n","    heapq.heappush(top_bigrams_per_first_word[first_word],\n","                   (freq, second_word))\n","    if len(top_bigrams_per_first_word[first_word]) > topk:\n","        heapq.heappop(top_bigrams_per_first_word[first_word])"]},{"cell_type":"code","execution_count":70,"id":"VPQL9Op7gxVA","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1739546909888,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"VPQL9Op7gxVA","outputId":"822e9ec5-7d20-4cfa-8ebe-b3c93883cc42"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(9, 'resources'), (216, 'gas'), (39, 'rubber')]"]},"metadata":{},"execution_count":70}],"source":["top_bigrams_per_first_word['natural']"]},{"cell_type":"code","execution_count":71,"id":"TiKZpFjZg3uA","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739546909888,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"TiKZpFjZg3uA"},"outputs":[],"source":["# Convert the heap to a simple list for each first word\n","for first_word in top_bigrams_per_first_word:\n","    sorted_bigrams = sorted(\n","        top_bigrams_per_first_word[first_word], reverse=True)\n","    top_bigrams_list = []\n","    for freq, second_word in sorted_bigrams:\n","        top_bigrams_list.append(second_word)\n","    top_bigrams_per_first_word[first_word] = top_bigrams_list\n","\n","# Use these filtered bigrams to create a ConditionalFreqDist\n","filtered_bi_grams = []\n","for first_word in top_bigrams_per_first_word:\n","    for second_word in top_bigrams_per_first_word[first_word]:\n","        filtered_bi_grams.append((first_word, second_word))\n","\n","bi_gram_freq = ConditionalFreqDist(filtered_bi_grams)"]},{"cell_type":"code","execution_count":72,"id":"7G_mpRyqg7n4","metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1739546909888,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"},"user_tz":-330},"id":"7G_mpRyqg7n4"},"outputs":[],"source":["def generate_sentence(word, num_words):\n","    word =word.lower()\n","    for _ in range(num_words):\n","        print(word, end=' ')\n","        next_words = [item for item, freq in bi_gram_freq[word].items()]\n","        if len(next_words) > 0:\n","            # Randomly choose a next word\n","            word = random.choice(next_words)\n","        else:\n","            break  # Break if the word has no following words\n","    print()"]},{"cell_type":"code","execution_count":74,"id":"HkgJQqs6n1Cy","metadata":{"id":"HkgJQqs6n1Cy","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739549694745,"user_tz":-330,"elapsed":3065,"user":{"displayName":"Vaibhav Reddy","userId":"11269168650758548799"}},"outputId":"a7fcbaee-da5b-45bf-fd60-2380082c97c6"},"outputs":[{"output_type":"stream","name":"stdout","text":["the dollar s . the u trans lux corp lt xon unit of a new company said it has a share in the company said . s lt c and other than a year shr loss shr profit of a year shr profit 2 pct . the u . s lt bp . 5 pct in the dollar . 5 mln dlrs in a new zealand s stock . s lt xon mobil said . the u card rates . s lt bp s stock . 5 pct in 1986 87 03 09 dlrs in a year ago period ended \n"]}],"source":["import random\n","from nltk.probability import ConditionalFreqDist\n","from nltk.util import bigrams\n","from nltk import FreqDist\n","\n","# ... (previous code to create words list)\n","\n","# Generate bigrams\n","bi_grams = list(bigrams(words))\n","\n","# Calculate frequency distribution for each bigram\n","bi_gram_freq_dist = FreqDist(bi_grams)\n","\n","# ... (code to create top_bigrams_per_first_word)\n","\n","# Use these filtered bigrams to create a ConditionalFreqDist\n","filtered_bi_grams = []\n","for first_word in top_bigrams_per_first_word:\n","    for second_word in top_bigrams_per_first_word[first_word]:\n","        filtered_bi_grams.append((first_word, second_word))\n","\n","bi_gram_freq = ConditionalFreqDist(filtered_bi_grams)\n","\n","def generate_sentence(word, num_words):\n","    word = word.lower()\n","    for _ in range(num_words):\n","        print(word, end=' ')\n","        # Now bi_gram_freq is accessible\n","        next_words = [item for item, freq in bi_gram_freq[word].items()]\n","        if len(next_words) > 0:\n","            word = random.choice(next_words)\n","        else:\n","            break\n","    print()\n","\n","generate_sentence('the', 100)"]}],"metadata":{"colab":{"provenance":[{"file_id":"18F4DIrsg-sscGY4BVJjadTfUJP2mijkl","timestamp":1739536047063}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}